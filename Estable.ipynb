{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estable",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mlepmnzc0xP",
        "colab_type": "code",
        "outputId": "c503fe97-fd9c-4d52-a890-d8bac0c09e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load LSTM network and generate text\n",
        "import sys\n",
        "import os\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyog0JlKc88-",
        "colab_type": "code",
        "outputId": "673d6b52-c7d1-4ed9-bd8d-0f8ff1fc939c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zij8HUrp24y",
        "colab_type": "text"
      },
      "source": [
        "#Cargar Texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJion6WwD7Fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = '/content/drive/Shared drives/test/allSongs.txt'\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()[:30150]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48kUsUcfp5Rd",
        "colab_type": "text"
      },
      "source": [
        "#Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQglilTpdBI4",
        "colab_type": "code",
        "outputId": "dd8c32e6-560a-48a8-c4bc-28473aa2995e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  30150\n",
            "Total Vocab:  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQU5-yj2ev1K",
        "colab_type": "code",
        "outputId": "96b9c095-3888-4704-a0e6-13358aa52319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 300\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "#print(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  29850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cysDcs-KaZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6GXlfYbp--q",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VB6UOrRe0QE",
        "colab_type": "code",
        "outputId": "70e3100d-391d-41c0-b718-689bf2a189f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"/content/drive/Shared drives/test/weights/weights-improvement-last-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=1, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=80, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.8784\n",
            "Epoch 2/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.7728\n",
            "Epoch 3/80\n",
            "30000/30000 [==============================] - 236s 8ms/step - loss: 2.6956\n",
            "Epoch 4/80\n",
            "30000/30000 [==============================] - 231s 8ms/step - loss: 2.6330\n",
            "Epoch 5/80\n",
            "30000/30000 [==============================] - 232s 8ms/step - loss: 2.5792\n",
            "Epoch 6/80\n",
            "30000/30000 [==============================] - 231s 8ms/step - loss: 2.4883\n",
            "Epoch 7/80\n",
            "30000/30000 [==============================] - 234s 8ms/step - loss: 2.3686\n",
            "Epoch 8/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.2562\n",
            "Epoch 9/80\n",
            "30000/30000 [==============================] - 236s 8ms/step - loss: 2.1693\n",
            "Epoch 10/80\n",
            "30000/30000 [==============================] - 236s 8ms/step - loss: 2.0997\n",
            "Epoch 11/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.0121\n",
            "Epoch 12/80\n",
            "30000/30000 [==============================] - 235s 8ms/step - loss: 1.9331\n",
            "Epoch 13/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 1.8480\n",
            "Epoch 14/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 1.7589\n",
            "Epoch 15/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 1.6769\n",
            "Epoch 16/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 1.6292\n",
            "Epoch 17/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 1.5180\n",
            "Epoch 18/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 1.4449\n",
            "Epoch 19/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 1.3674\n",
            "Epoch 20/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 1.3009\n",
            "Epoch 21/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 1.2310\n",
            "Epoch 22/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 1.1938\n",
            "Epoch 23/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 1.1037\n",
            "Epoch 24/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 1.0331\n",
            "Epoch 25/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 0.9783\n",
            "Epoch 26/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 0.9257\n",
            "Epoch 27/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 0.8638\n",
            "Epoch 28/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 0.8159\n",
            "Epoch 29/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 0.7699\n",
            "Epoch 30/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 1.9041\n",
            "Epoch 31/80\n",
            "30000/30000 [==============================] - 242s 8ms/step - loss: 3.0859\n",
            "Epoch 32/80\n",
            "30000/30000 [==============================] - 241s 8ms/step - loss: 2.9471\n",
            "Epoch 33/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 2.8870\n",
            "Epoch 34/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.8620\n",
            "Epoch 35/80\n",
            "30000/30000 [==============================] - 236s 8ms/step - loss: 2.8468\n",
            "Epoch 36/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.8380\n",
            "Epoch 37/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.8290\n",
            "Epoch 38/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.8227\n",
            "Epoch 39/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.8168\n",
            "Epoch 40/80\n",
            "30000/30000 [==============================] - 236s 8ms/step - loss: 2.8058\n",
            "Epoch 41/80\n",
            "30000/30000 [==============================] - 237s 8ms/step - loss: 2.7904\n",
            "Epoch 42/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.7710\n",
            "Epoch 43/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 2.7460\n",
            "Epoch 44/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.7231\n",
            "Epoch 45/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.6960\n",
            "Epoch 46/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 2.6697\n",
            "Epoch 47/80\n",
            "30000/30000 [==============================] - 238s 8ms/step - loss: 2.6400\n",
            "Epoch 48/80\n",
            "30000/30000 [==============================] - 240s 8ms/step - loss: 2.6026\n",
            "Epoch 49/80\n",
            "30000/30000 [==============================] - 239s 8ms/step - loss: 2.5651\n",
            "Epoch 50/80\n",
            "30000/30000 [==============================] - 241s 8ms/step - loss: 2.5043\n",
            "Epoch 51/80\n",
            "22592/30000 [=====================>........] - ETA: 59s - loss: 2.4391"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAbH03cJqLHC",
        "colab_type": "text"
      },
      "source": [
        "#Load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZckH4RcIh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/drive/Shared drives/test/weights/weights-improvement-last-29-0.7699.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lItSAL-QqNer",
        "colab_type": "text"
      },
      "source": [
        "#Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWW5b5ae4FV",
        "colab_type": "code",
        "outputId": "7105bf27-914d-4eb6-d82d-d85cf21bddca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"  cualquier argumento\n",
            "no le importa si su destino es violento\n",
            "va tranquila la bala no tiene sentimientos\n",
            "como un secreto que no quieres escuchar\n",
            "la bala va dicindolo todo sin hablar\n",
            "sin levantar sospecha asegura su matanza\n",
            "por eso tiene llena de plomo su panza\n",
            "para llegar a su presa no necesita ojos\n",
            " \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyAhE0yUqWCH",
        "colab_type": "text"
      },
      "source": [
        "#Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBurCo8_qTij",
        "colab_type": "code",
        "outputId": "ed196ae4-87ab-4494-c182-7b30a1782bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y ms cuando el camino se po te pe estua t mos cabilando alu tnamas contamas cuenqoseal contr aonuellos\n",
            "los paruido sodos los mieas s senas son la bira\n",
            "\n",
            "en mi cabeza tin ducilano de ror puestro con sarario muertro cuando te me cinvral\n",
            "con el ciruo don iosirade gorua de la mlna\n",
            "ce lo que sodre\n",
            "el moeo\n",
            "cono un fuera\n",
            "s te na empujamo monga sin margarina\n",
            "y se la empujamo monga sin margarina\n",
            "y se la empujamo monga sin margarina\n",
            "y se la empujamos monga bien monga\n",
            "\n",
            "yoy soy lo que mo esca me ealelina por las matal s ce tenter en un par de asrelloo\n",
            "so se penue en eamon domo un fuera\n",
            "\n",
            "el mamon lo que suere\n",
            "es por que algunan por uue caricndo en ca ciroo an como eo agua bendita\n",
            "es ltuier areo eo mo henerina parue no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque no le duela\n",
            "paque n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}